{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:25:35.572561Z",
     "iopub.status.busy": "2022-07-14T04:25:35.571600Z",
     "iopub.status.idle": "2022-07-14T04:25:47.591300Z",
     "shell.execute_reply": "2022-07-14T04:25:47.590195Z",
     "shell.execute_reply.started": "2022-07-14T04:25:35.572509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/balechen/opt/anaconda3/lib/python3.8/site-packages (1.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/balechen/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T03:13:26.780326Z",
     "iopub.status.busy": "2022-07-14T03:13:26.779915Z",
     "iopub.status.idle": "2022-07-14T03:13:30.162355Z",
     "shell.execute_reply": "2022-07-14T03:13:30.161304Z",
     "shell.execute_reply.started": "2022-07-14T03:13:26.780235Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:26:09.310533Z",
     "iopub.status.busy": "2022-07-14T04:26:09.310177Z",
     "iopub.status.idle": "2022-07-14T04:26:10.628981Z",
     "shell.execute_reply": "2022-07-14T04:26:10.627994Z",
     "shell.execute_reply.started": "2022-07-14T04:26:09.310503Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data/SemEval-2015-Scraped.xlsx')[['content', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T09:02:17.539373Z",
     "iopub.status.busy": "2022-07-13T09:02:17.539028Z",
     "iopub.status.idle": "2022-07-13T09:02:17.930972Z",
     "shell.execute_reply": "2022-07-13T09:02:17.930027Z",
     "shell.execute_reply.started": "2022-07-13T09:02:17.539344Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T09:02:20.689569Z",
     "iopub.status.busy": "2022-07-13T09:02:20.689187Z",
     "iopub.status.idle": "2022-07-13T09:02:20.696910Z",
     "shell.execute_reply": "2022-07-13T09:02:20.695652Z",
     "shell.execute_reply.started": "2022-07-13T09:02:20.689518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9915125 1.3768921934355465\n"
     ]
    }
   ],
   "source": [
    "labels = data.label.to_numpy()\n",
    "print(np.mean(labels),np.std(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:25:24.533254Z",
     "iopub.status.busy": "2022-07-14T04:25:24.532693Z",
     "iopub.status.idle": "2022-07-14T04:25:24.542845Z",
     "shell.execute_reply": "2022-07-14T04:25:24.541925Z",
     "shell.execute_reply.started": "2022-07-14T04:25:24.533219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffcb258d190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "SEED = 2022\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T03:13:42.645464Z",
     "iopub.status.busy": "2022-07-14T03:13:42.644651Z",
     "iopub.status.idle": "2022-07-14T03:13:43.282401Z",
     "shell.execute_reply": "2022-07-14T03:13:43.281388Z",
     "shell.execute_reply.started": "2022-07-14T03:13:42.645420Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:18:03.374506Z",
     "iopub.status.busy": "2022-07-14T04:18:03.374171Z",
     "iopub.status.idle": "2022-07-14T04:18:03.387605Z",
     "shell.execute_reply": "2022-07-14T04:18:03.386778Z",
     "shell.execute_reply.started": "2022-07-14T04:18:03.374471Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:57:05.443473Z",
     "iopub.status.busy": "2022-07-14T04:57:05.443139Z",
     "iopub.status.idle": "2022-07-14T04:57:07.154016Z",
     "shell.execute_reply": "2022-07-14T04:57:07.153065Z",
     "shell.execute_reply.started": "2022-07-14T04:57:05.443444Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:57:11.650185Z",
     "iopub.status.busy": "2022-07-14T04:57:11.649767Z",
     "iopub.status.idle": "2022-07-14T04:57:11.661124Z",
     "shell.execute_reply": "2022-07-14T04:57:11.660159Z",
     "shell.execute_reply.started": "2022-07-14T04:57:11.650151Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode('I love it 😄 😔 💗'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:25:12.359394Z",
     "iopub.status.busy": "2022-07-14T04:25:12.359062Z",
     "iopub.status.idle": "2022-07-14T04:25:15.926425Z",
     "shell.execute_reply": "2022-07-14T04:25:15.925448Z",
     "shell.execute_reply.started": "2022-07-14T04:25:12.359366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5314357df4c6695505e37daa47180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a2ab338729447080898894dfb311aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1302ea1a884610a90208663bfa9a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:25:18.239311Z",
     "iopub.status.busy": "2022-07-14T04:25:18.238897Z",
     "iopub.status.idle": "2022-07-14T04:25:18.247839Z",
     "shell.execute_reply": "2022-07-14T04:25:18.246567Z",
     "shell.execute_reply.started": "2022-07-14T04:25:18.239275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> I love it 😄 😔 💗</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode('I love it 😄 😔 💗'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:57:26.978911Z",
     "iopub.status.busy": "2022-07-14T04:57:26.978555Z",
     "iopub.status.idle": "2022-07-14T04:57:26.984734Z",
     "shell.execute_reply": "2022-07-14T04:57:26.983709Z",
     "shell.execute_reply.started": "2022-07-14T04:57:26.978880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the special tokens and configurations\n",
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "max_input_length = tokenizer.max_model_input_sizes['xlm-roberta-base']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:57:29.020636Z",
     "iopub.status.busy": "2022-07-14T04:57:29.020295Z",
     "iopub.status.idle": "2022-07-14T04:57:29.025621Z",
     "shell.execute_reply": "2022-07-14T04:57:29.024387Z",
     "shell.execute_reply.started": "2022-07-14T04:57:29.020606Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:59:44.899410Z",
     "iopub.status.busy": "2022-07-14T04:59:44.898726Z",
     "iopub.status.idle": "2022-07-14T04:59:44.996830Z",
     "shell.execute_reply": "2022-07-14T04:59:44.995776Z",
     "shell.execute_reply.started": "2022-07-14T04:59:44.899364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (6000,)\n",
      "shape of test data is (2000,)\n"
     ]
    }
   ],
   "source": [
    "X,y = data['content'].values, data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(f'shape of train data is {X_train.shape}')\n",
    "print(f'shape of test data is {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper and axis must be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5f556648524c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3177\u001b[0m ):\n\u001b[1;32m   3178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3179\u001b[0;31m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   3180\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3181\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1582\u001b[0m                  errwidth, capsize, dodge):\n\u001b[1;32m   1583\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0m\u001b[1;32m   1585\u001b[0m                                  order, hue_order, units)\n\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# Group the numeric data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 plot_data, value_label = self._group_longform(vals, groups,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                               group_names)\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m_group_longform\u001b[0;34m(self, vals, grouper, order)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Group the val data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mgrouped_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m         return SeriesGroupBy(\n\u001b[0m\u001b[1;32m   1721\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# allow us to passing the actual Grouping as the gpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         ping = (\n\u001b[0;32m--> 828\u001b[0;31m             Grouping(\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0mgroup_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, grouper, obj, name, level, sort, observed, in_axis, dropna)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_grouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_convert_grouper\u001b[0;34m(axis, grouper)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grouper and axis must be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Grouper and axis must be same length"
     ]
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:59:41.379581Z",
     "iopub.status.busy": "2022-07-14T04:59:41.379027Z",
     "iopub.status.idle": "2022-07-14T04:59:41.390499Z",
     "shell.execute_reply": "2022-07-14T04:59:41.389425Z",
     "shell.execute_reply.started": "2022-07-14T04:59:41.379544Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # This cleans out all emojis!!!\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tokenize(x_train,y_train,x_val,y_val):\n",
    "#     word_list = []\n",
    "\n",
    "#     stop_words = set(stopwords.words('english')) \n",
    "#     for sent in x_train:\n",
    "#         for word in sent.lower().split():\n",
    "#             word = preprocess_string(word)\n",
    "#             if word not in stop_words and word != '':\n",
    "#                 word_list.append(word)\n",
    "  \n",
    "#     corpus = Counter(word_list)\n",
    "#     # sorting on the basis of most common words\n",
    "#     corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "#     # creating a dict\n",
    "#     onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "#     # tockenize\n",
    "#     final_list_train,final_list_test = [],[]\n",
    "#     for sent in x_train:\n",
    "#             final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "#                                      if preprocess_string(word) in onehot_dict.keys()])\n",
    "#     for sent in x_val:\n",
    "#             final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "#                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    final_list_train, final_list_test = [], []\n",
    "    for sent_1 in x_train:\n",
    "        final_list_train = tokenizer(preprocess_string(sent_1))\n",
    "    for sent_2 in x_val:\n",
    "        final_list_test = tokenizer(preprocess_string(sent_2))\n",
    "        \n",
    "    encoded_train = [1 if label == True else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label == True else 0 for label in y_val]\n",
    "    \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in data['content']:\n",
    "    tokens = tokenizer.encode(txt, max_length=512)\n",
    "    token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256]);\n",
    "plt.xlabel('Token count');\n",
    "print(max(token_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:00.154674Z",
     "iopub.status.busy": "2022-07-14T05:00:00.154112Z",
     "iopub.status.idle": "2022-07-14T05:00:00.162665Z",
     "shell.execute_reply": "2022-07-14T05:00:00.161808Z",
     "shell.execute_reply.started": "2022-07-14T05:00:00.154637Z"
    }
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tweets, targets, tokenizer, max_len):\n",
    "        self.tweets = tweets\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        tweets = str(self.tweets[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          tweets,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding='max_length',\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "          'tweet_text': tweets,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:05.044080Z",
     "iopub.status.busy": "2022-07-14T05:00:05.043539Z",
     "iopub.status.idle": "2022-07-14T05:00:05.050513Z",
     "shell.execute_reply": "2022-07-14T05:00:05.049263Z",
     "shell.execute_reply.started": "2022-07-14T05:00:05.044037Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_loader(X, y, tokenizer, max_len, batch_size):\n",
    "    ds = TweetDataset(\n",
    "    tweets=X,\n",
    "    targets=y,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:11.771662Z",
     "iopub.status.busy": "2022-07-14T05:00:11.770678Z",
     "iopub.status.idle": "2022-07-14T05:00:11.777204Z",
     "shell.execute_reply": "2022-07-14T05:00:11.775903Z",
     "shell.execute_reply.started": "2022-07-14T05:00:11.771614Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 128\n",
    "\n",
    "train_data_loader = create_data_loader(X_train, y_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(X_test, y_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:27:04.317779Z",
     "iopub.status.busy": "2022-07-14T04:27:04.317306Z",
     "iopub.status.idle": "2022-07-14T04:27:04.324886Z",
     "shell.execute_reply": "2022-07-14T04:27:04.323618Z",
     "shell.execute_reply.started": "2022-07-14T04:27:04.317716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T04:59:33.502731Z",
     "iopub.status.busy": "2022-07-14T04:59:33.502400Z",
     "iopub.status.idle": "2022-07-14T04:59:33.823892Z",
     "shell.execute_reply": "2022-07-14T04:59:33.823014Z",
     "shell.execute_reply.started": "2022-07-14T04:59:33.502703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_data_loader)\n",
    "sample = dataiter.next()\n",
    "print(sample.keys())\n",
    "print(sample['input_ids'].shape)\n",
    "print(sample['attention_mask'].shape)\n",
    "print(sample['targets'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:17.581778Z",
     "iopub.status.busy": "2022-07-14T05:00:17.581407Z",
     "iopub.status.idle": "2022-07-14T05:00:19.543164Z",
     "shell.execute_reply": "2022-07-14T05:00:19.542035Z",
     "shell.execute_reply.started": "2022-07-14T05:00:17.581732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2f202cb4be478ea6dddd138879aade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:29.373739Z",
     "iopub.status.busy": "2022-07-14T05:00:29.373399Z",
     "iopub.status.idle": "2022-07-14T05:00:34.891152Z",
     "shell.execute_reply": "2022-07-14T05:00:34.890030Z",
     "shell.execute_reply.started": "2022-07-14T05:00:29.373710Z"
    }
   },
   "outputs": [],
   "source": [
    "trial = nn.LSTM(input_size=768,\n",
    "       hidden_size=512,\n",
    "       num_layers=2,\n",
    "       bidirectional=True,\n",
    "       batch_first=True)\n",
    "hidden = trial(bert(input_ids=sample['input_ids'],\n",
    "          attention_mask=sample['attention_mask'])[0])[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(hidden.transpose(0,1), start_dim = 1, end_dim= 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:41.870655Z",
     "iopub.status.busy": "2022-07-14T05:00:41.870323Z",
     "iopub.status.idle": "2022-07-14T05:00:41.880761Z",
     "shell.execute_reply": "2022-07-14T05:00:41.879657Z",
     "shell.execute_reply.started": "2022-07-14T05:00:41.870625Z"
    }
   },
   "outputs": [],
   "source": [
    "class BERT_BiLSTM_FFF_Cls(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, hidden_dim, bidirectional):\n",
    "        super(BERT_BiLSTM_FFF_Cls, self).__init__()\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bert = bert\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                           hidden_size=self.hidden_dim,\n",
    "                           num_layers=2,\n",
    "                           bidirectional=self.bidirectional,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "                    nn.Linear(self.hidden_dim * 4, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 1)\n",
    "                   )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.bert(\n",
    "              input_ids=input_ids,\n",
    "              attention_mask=attention_mask\n",
    "            )[0]\n",
    "        \n",
    "        last_hidden = self.lstm(embeddings)[1][0]\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        last_hidden = self.drop(torch.flatten(last_hidden.transpose(0,1), start_dim=1, end_dim=2))\n",
    "        \n",
    "        return self.out(last_hidden).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:48.481653Z",
     "iopub.status.busy": "2022-07-14T05:00:48.481316Z",
     "iopub.status.idle": "2022-07-14T05:00:48.580774Z",
     "shell.execute_reply": "2022-07-14T05:00:48.579722Z",
     "shell.execute_reply.started": "2022-07-14T05:00:48.481623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 512\n",
    "bidirectional = True\n",
    "EPOCHS = 10\n",
    "lr=0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "baseline_1 = BERT_BiLSTM_FFF_Cls(bert, hidden_dim, bidirectional)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(baseline_1.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:50.910186Z",
     "iopub.status.busy": "2022-07-14T05:00:50.909703Z",
     "iopub.status.idle": "2022-07-14T05:00:50.930519Z",
     "shell.execute_reply": "2022-07-14T05:00:50.928823Z",
     "shell.execute_reply.started": "2022-07-14T05:00:50.910153Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                )\n",
    "#         print(outputs.dtype)\n",
    "#         _,preds = torch.max(outputs, dim = 1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "#         prediction_error += torch.sum(torch.abs(targets - outputs))\n",
    "#         correct_predictions += torch.sum(preds == torch.max(targets, dim = 1)[1])\n",
    "        print(f'Iteration loss: {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#     return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "    return np.mean(losses), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:52.962631Z",
     "iopub.status.busy": "2022-07-14T05:00:52.962298Z",
     "iopub.status.idle": "2022-07-14T05:00:52.970804Z",
     "shell.execute_reply": "2022-07-14T05:00:52.969480Z",
     "shell.execute_reply.started": "2022-07-14T05:00:52.962601Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "            )\n",
    "#             _, preds = torch.max(outputs, dim=1)\n",
    "#             prediction_error += torch.sum(torch.abs(targets - outputs))\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "#             correct_predictions += torch.sum(preds == torch.max(targets, dim = 1)[1])\n",
    "            losses.append(loss.item())\n",
    "\n",
    "#     return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "    return np.mean(losses), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-14T05:00:55.480672Z",
     "iopub.status.busy": "2022-07-14T05:00:55.480342Z",
     "iopub.status.idle": "2022-07-14T05:10:22.439568Z",
     "shell.execute_reply": "2022-07-14T05:10:22.438628Z",
     "shell.execute_reply.started": "2022-07-14T05:00:55.480644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Iteration loss: 0.7799904942512512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/375 [00:02<17:16,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 1.3147494792938232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/375 [00:05<16:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 1.2357288599014282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/375 [00:08<16:55,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 3.205643653869629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/375 [00:10<16:33,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 3.4536702632904053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/375 [00:13<16:03,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 1.6182652711868286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/375 [00:15<15:33,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 1.3090646266937256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/375 [00:18<15:21,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.43229442834854126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/375 [00:20<15:15,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 2.0228652954101562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/375 [00:23<15:08,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 2.543642520904541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 10/375 [00:25<14:57,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.6657606959342957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 11/375 [00:27<14:49,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.5885132551193237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 12/375 [00:30<15:07,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.4770420789718628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 13/375 [00:33<15:32,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.59141606092453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 14/375 [00:35<15:31,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 0.48445501923561096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 15/375 [00:38<15:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 5.235469818115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 16/375 [00:41<15:36,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 2.6672439575195312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 17/375 [00:43<15:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 3.5309414863586426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 18/375 [00:46<15:11,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 1.112640142440796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 19/375 [00:48<15:10,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration loss: 3.093787670135498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/375 [00:51<15:19,  2.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6e1a267c2cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     train_acc, train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbaseline_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-d2834ec39a67>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, n_examples)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-9f99e8aa8fd7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             embeddings = self.bert(\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         )\n\u001b[0;32m--> 848\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 )\n\u001b[1;32m    523\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    525\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 336\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "baseline_1.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "    baseline_1,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device,\n",
    "    len(X_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "    baseline_1,\n",
    "    test_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(X_test)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(baseline_1.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T09:24:00.711192Z",
     "iopub.status.busy": "2022-07-13T09:24:00.710612Z",
     "iopub.status.idle": "2022-07-13T09:24:00.718354Z",
     "shell.execute_reply": "2022-07-13T09:24:00.717385Z",
     "shell.execute_reply.started": "2022-07-13T09:24:00.711154Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(y_test, axis = 0)/y_test.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
